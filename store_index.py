# store_index.py

from dotenv import load_dotenv
import os

from src.helper import (
    load_pdf_file,
    filter_to_minimal_docs,
    text_split,
    download_embeddings
)

from langchain_community.vectorstores import FAISS

# ------------------------
# Load env
# ------------------------
load_dotenv()

# ------------------------
# Load & process PDFs
# ------------------------
print("ğŸ“„ Loading PDFs...")
extracted_data = load_pdf_file("data")

print("ğŸ§¹ Cleaning documents...")
minimal_docs = filter_to_minimal_docs(extracted_data)

print("âœ‚ï¸ Splitting text into chunks...")
text_chunks = text_split(minimal_docs)

print(f"ğŸ“„ Total chunks created: {len(text_chunks)}")

# ------------------------
# Embeddings
# ------------------------
print("ğŸ”¢ Loading embedding model...")
embeddings = download_embeddings()

# ------------------------
# Create FAISS index
# ------------------------
print("ğŸ“¦ Creating FAISS index...")
vectorstore = FAISS.from_documents(
    documents=text_chunks,
    embedding=embeddings
)

# ------------------------
# Save FAISS index locally
# ------------------------
print("ğŸ’¾ Saving FAISS index to disk...")
vectorstore.save_local("faiss_index")

print("âœ… FAISS index created and saved successfully!")
